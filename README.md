# AIRA - AI Science Teacher ğŸ¤–ğŸ“š

<div align="center">

![AIRA Logo](https://img.shields.io/badge/AIRA-AI%20Teaching%20Assistant-blue?style=for-the-badge&logo=robot&logoColor=white)
![React](https://img.shields.io/badge/React-18.2.0-61DAFB?style=for-the-badge&logo=react)
![FastAPI](https://img.shields.io/badge/FastAPI-0.68.0-009688?style=for-the-badge&logo=fastapi)
![TypeScript](https://img.shields.io/badge/TypeScript-5.0.2-3178C6?style=for-the-badge&logo=typescript)

**Your Intelligent Science Teaching Assistant for Interactive Learning**

[Features](#features) â€¢ [Installation](#installation) â€¢ [Usage](#usage) â€¢ [API](#api) â€¢ [Structure](#project-structure)

</div>

## ğŸ¯ Overview

AIRA is an advanced AI-powered science teaching assistant that provides interactive, personalized learning experiences for students. It combines voice interaction, real-time media sequencing, and comprehensive lesson management to create an engaging educational environment.

## âœ¨ Features

### ğŸ¤ Multi-Modal Interaction
- **Voice Input**: Advanced speech recognition with real-time transcription
- **Text Input**: Traditional text-based queries
- **Smart Interruption**: Seamlessly interrupt and ask questions during lessons

### ğŸ­ Immersive Experience
- **Animated Robot Avatar**: Real-time lip-sync and facial animations
- **Media Sequencing**: Automatic display of images, videos, and explanations
- **Text-to-Speech**: Natural voice narration with visual subtitles

### ğŸ“š Comprehensive Learning
- **Lesson Index**: Structured curriculum with hierarchical topic organization
- **Session Notes**: Automatic note-taking with bullet-point summaries
- **Progress Tracking**: Persistent conversation memory across sessions

### ğŸ›  Technical Excellence
- **Real-time Processing**: Instant response with media queuing
- **Responsive Design**: Works seamlessly across all devices
- **Type Safety**: Full TypeScript implementation
- **Modular Architecture**: Clean, maintainable code structure

## ğŸš€ Quick Start

### Prerequisites
- Node.js 16+ and npm
- Python 3.8+
- Groq API key (for AI responses)

### Installation

1. **Clone the Repository**
```bash
git clone <your-repo-url>
cd AIRA
```

2. **Frontend Setup**
```bash
# Install dependencies
npm install

# Start development server
npm run dev
```

3. **Backend Setup**
```bash
# Install Python dependencies
pip install -r requirements.txt

# Set up environment variables
cp .env.example .env
# Add your Groq API key to .env

# Start backend server
python server.py
```

4. **Access the Application**
- Frontend: http://localhost:5173
- Backend API: http://localhost:8000

## ğŸ® Usage

### Home Page
- **AIRA Landing**: Welcome screen with two main options
- **ASK AIRA**: Direct interaction with the AI teacher
- **LESSON INDEX**: Browse structured curriculum topics

### Interactive Learning
1. **Start a Lesson**: Choose from lesson index or ask directly
2. **Engage with Content**: Watch videos, view images, listen to explanations
3. **Ask Questions**: Interrupt anytime with voice or text
4. **Review Notes**: Access automatically generated session notes

### Voice Commands
- Click the microphone icon to start speaking
- System automatically detects speech and silence
- Real-time transcription with confidence indicators

## ğŸ— Project Structure

```
AIRA/
â”œâ”€â”€ src/                    # Frontend React Application
â”‚   â”œâ”€â”€ components/         # React Components
â”‚   â”‚   â”œâ”€â”€ HomePage.tsx    # Landing page
â”‚   â”‚   â”œâ”€â”€ LessonIndex.tsx # Curriculum browser
â”‚   â”‚   â”œâ”€â”€ RobotAvatar.tsx # Animated robot
â”‚   â”‚   â”œâ”€â”€ MessageDisplay.tsx # Subtitles
â”‚   â”‚   â”œâ”€â”€ InputBar.tsx    # Voice/text input
â”‚   â”‚   â””â”€â”€ NotesModal.tsx  # Session notes
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â””â”€â”€ useMediaSequencer.ts # Media management
â”‚   â”œâ”€â”€ services/           # Business logic
â”‚   â”‚   â”œâ”€â”€ apiService.ts   # Backend communication
â”‚   â”‚   â”œâ”€â”€ ttsService.ts   # Text-to-speech
â”‚   â”‚   â””â”€â”€ notesService.ts # Session notes
â”‚   â”œâ”€â”€ types.ts           # TypeScript definitions
â”‚   â””â”€â”€ constants.ts       # Application constants
â”œâ”€â”€ backend/               # Python FastAPI Server
â”‚   â”œâ”€â”€ server.py         # Main API server
â”‚   â”œâ”€â”€ agent.py          # AI agent with LangChain
â”‚   â”œâ”€â”€ agent_tools.py    # Custom tools for AI
â”‚   â”œâ”€â”€ utils.py          # Utility functions
â”‚   â””â”€â”€ knowledgebase/    # Educational content
â””â”€â”€ configuration/
    â”œâ”€â”€ package.json      # Node.js dependencies
    â”œâ”€â”€ requirements.txt  # Python dependencies
    â””â”€â”€ vite.config.ts   # Build configuration
```

## ğŸ”§ API Endpoints

### Backend Routes
- `POST /chat` - Get AI teacher responses
- `POST /transcribe` - Convert audio to text
- `GET /images/*` - Serve educational images

### Frontend Routes
- `/` - Home page with AIRA introduction
- `/ask` - Interactive chat interface
- `/lessons` - Curriculum topic browser

## ğŸ¯ Key Components

### ğŸ¤– RobotAvatar
- Real-time facial animations
- Lip-sync with speech
- Emotional expressions
- Media overlay support

### ğŸ¤ InputBar
- Dual input modes (voice/text)
- Smart silence detection
- Real-time audio visualization
- Session control buttons

### ğŸ“– LessonIndex
- Hierarchical topic organization
- Expandable/collapsible sections
- One-click topic selection
- Progress indicators

### ğŸ“ NotesModal
- Automatic session summarization
- Bullet-point formatting
- Copy-to-clipboard functionality
- Persistent local storage

## ğŸ”„ Media Sequencing

AIRA intelligently sequences learning content:

1. **Text Explanation** â†’ TTS with subtitles
2. **Visual Aids** â†’ Images with descriptions  
3. **Video Content** â†’ YouTube integration
4. **Interactive Q&A** â†’ Real-time interruptions

## ğŸ›  Development

### Adding New Features
1. Create component in `src/components/`
2. Add TypeScript definitions in `types.ts`
3. Implement services in `src/services/`
4. Update routing in `App.tsx`

### Backend Extensions
1. Add new tools in `agent_tools.py`
2. Create API routes in `server.py`
3. Update agent prompts in `agent.py`

### Environment Variables
```env
GROQ_API_KEY=your_groq_api_key
OPENAI_API_KEY=optional_openai_key
BACKEND_URL=http://localhost:8000
```

## ğŸ“Š Performance

- **Fast Response Times**: <2s for AI responses
- **Real-time Processing**: Instant voice transcription
- **Smooth Animations**: 60fps robot animations
- **Optimized Media**: Efficient image/video loading

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **React Team** for the amazing frontend framework
- **FastAPI** for high-performance backend API
- **Groq** for lightning-fast AI inference
- **LangChain** for powerful AI agent capabilities
- **Tailwind CSS** for beautiful, responsive styling

## ğŸ“ Support

For support and questions:
- ğŸ“§ Email: 

---

<div align="center">

**Made with â¤ï¸ for the future of education**

*"Empowering every student with personalized AI tutoring"*

[â¬† Back to Top](#aira---ai-science-teacher-)

</div>